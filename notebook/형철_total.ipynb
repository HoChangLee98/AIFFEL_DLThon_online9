{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "780e594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../model\")\n",
    "\n",
    "## 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## 시각화 툴\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## encoding \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "## vocabulary\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "## tokenizer \n",
    "from transformers import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "## preprocessor\n",
    "from custom_preprocessor import Preprocessor\n",
    "\n",
    "## model\n",
    "from transformer_v1 import transformer\n",
    "\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8a0ec",
   "metadata": {},
   "source": [
    "# hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f0d639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 파라미터\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "# 학습 파라미터\n",
    "EPOCHS = 1\n",
    "\n",
    "# 모델 구조 파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34978d",
   "metadata": {},
   "source": [
    "# Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40d0e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor()\n",
    "preprocessed_train, preprocessed_test = preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f50788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train[\"conversation\"].apply(lambda x: len(x.split())).max()\n",
    "\n",
    "## CLASS_NAMES에 '일반 대화'를 포함시킴\n",
    "CLASS_NAMES = ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화', '일반 대화']\n",
    "\n",
    "# 수동 매핑 설정\n",
    "class_mapping = {\n",
    "    '협박 대화': 0,\n",
    "    '갈취 대화': 1,\n",
    "    '직장 내 괴롭힘 대화': 2,\n",
    "    '기타 괴롭힘 대화': 3,\n",
    "    '일반 대화': 4\n",
    "}\n",
    "\n",
    "\n",
    "# 'class' 열을 수동 매핑 적용하기 전에 문자열로 변환\n",
    "preprocessed_train['class'] = preprocessed_train['class'].astype(str).map(class_mapping)\n",
    "labels = preprocessed_train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e642c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 특수 토큰 ID 확인\n",
    "CLS_TOKEN_ID = tokenizer.cls_token_id  # [CLS] 토큰 ID\n",
    "SEP_TOKEN_ID = tokenizer.sep_token_id  # [SEP] 토큰 ID\n",
    "UNK_TOKEN_ID = tokenizer.unk_token_id  # [UNK] 토큰 ID\n",
    "PAD_TOKEN_ID = tokenizer.pad_token_id  # [PAD] 토큰 ID\n",
    "\n",
    "# 각 문장에 [CLS], [SEP] 추가\n",
    "def add_special_tokens(tokenized_texts):\n",
    "    return [[CLS_TOKEN_ID] + tokenizer.convert_tokens_to_ids(tokens) + [SEP_TOKEN_ID] for tokens in tokenized_texts]\n",
    "\n",
    "## 토크나이징\n",
    "tokenized_train = [tokenizer.tokenize(con) for con in preprocessed_train['conversation'].tolist()]\n",
    "tokenized_test = [tokenizer.tokenize(con) for con in preprocessed_test['text'].tolist()]\n",
    "\n",
    "## [CLS], [SEP] 토큰 추가\n",
    "token_id_train = add_special_tokens(tokenized_train)\n",
    "token_id_test = add_special_tokens(tokenized_test)\n",
    "\n",
    "# 패딩과 트렁케이션 설정\n",
    "## 문장의 max length를 test 문장의 최대 길이로 설정한다. \n",
    "## padding은 앞에서부터 진행\n",
    "## max길이를 넘어가면 앞에서부터 자른다. -> 한국말은 끝까지 들어야하므로..\n",
    "token_id_train = pad_sequences(token_id_train, maxlen=191, dtype='long', padding='pre', truncating='pre', value=PAD_TOKEN_ID)\n",
    "token_id_test = pad_sequences(token_id_test, maxlen=191, dtype='long', padding='pre', truncating='pre', value=PAD_TOKEN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b3cf662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4976, 191)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8fb086dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_rate = 0.2\n",
    "val_size_rate = 0.1\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "\n",
    "# 시드값 설정\n",
    "seed = 1004\n",
    "X_train, X_test, y_train, y_test = train_test_split(token_id_train, labels, test_size=test_size_rate, stratify=labels, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size_rate, stratify=y_train, random_state=seed)\n",
    "\n",
    "# 클래스 가중치 계산 (클래스 4 포함)\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# 각 샘플에 가중치 할당\n",
    "sample_weights = np.array([class_weights[y] for y in y_train])\n",
    "\n",
    "# tf.data.Dataset으로 변환 (sample_weight 포함)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train, sample_weights))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "# 데이터셋을 섞고, 배치 처리\n",
    "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557956e",
   "metadata": {},
   "source": [
    "# Model 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adfb5764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    1310208     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 256)          0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256)          0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "linear_hidden_layer (Dense)     (None, 1028)         264196      dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            5145        linear_hidden_layer[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,579,549\n",
      "Trainable params: 1,579,549\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "VOCAB_SIZE = 1000\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2cc42e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train\n",
    "y_true_classes = tf.argmax(y_train, axis=-1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3fd3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true, axis=-1)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=False)(y_true, y_pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), 0.5),K.floatx())\n",
    "    true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "    recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall_ratio\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), 0.5), K.floatx())\n",
    "    true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(y_pred)\n",
    "    precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision_ratio\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "706c1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c36fb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[f1_m])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca07a5ec",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "929789c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56/56 [==============================] - 4s 76ms/step - loss: 1.5956 - f1_m: 0.0000e+00 - val_loss: 1.5826 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 4s 68ms/step - loss: 1.5750 - f1_m: 0.0000e+00 - val_loss: 1.5552 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 4s 68ms/step - loss: 1.5506 - f1_m: 0.0062 - val_loss: 1.5280 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 4s 68ms/step - loss: 1.5120 - f1_m: 0.0599 - val_loss: 1.4916 - val_f1_m: 0.2050\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 4s 68ms/step - loss: 1.4816 - f1_m: 0.2505 - val_loss: 1.4850 - val_f1_m: 0.3906\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 4s 68ms/step - loss: 1.4733 - f1_m: 0.2394 - val_loss: 1.4914 - val_f1_m: 0.4450\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 4s 69ms/step - loss: 1.4757 - f1_m: 0.2506 - val_loss: 1.4353 - val_f1_m: 0.1195\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 4s 69ms/step - loss: 1.4532 - f1_m: 0.2667 - val_loss: 1.4632 - val_f1_m: 0.1316\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 4s 69ms/step - loss: 1.4401 - f1_m: 0.2566 - val_loss: 1.4339 - val_f1_m: 0.2795\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 4s 69ms/step - loss: 1.4445 - f1_m: 0.2508 - val_loss: 1.4527 - val_f1_m: 0.4529\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 4s 69ms/step - loss: 1.4479 - f1_m: 0.2558 - val_loss: 1.4383 - val_f1_m: 0.4393\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 4s 69ms/step - loss: 1.4383 - f1_m: 0.2538 - val_loss: 1.4324 - val_f1_m: 0.4036\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 4s 69ms/step - loss: 1.4412 - f1_m: 0.2897 - val_loss: 1.4293 - val_f1_m: 0.4814\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 4s 69ms/step - loss: 1.4384 - f1_m: 0.2514 - val_loss: 1.4797 - val_f1_m: 0.5344\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.4290 - f1_m: 0.3105 - val_loss: 1.4410 - val_f1_m: 0.4333\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.4322 - f1_m: 0.3113 - val_loss: 1.4860 - val_f1_m: 0.5626\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.4192 - f1_m: 0.3070 - val_loss: 1.4377 - val_f1_m: 0.4302\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.4178 - f1_m: 0.2944 - val_loss: 1.4410 - val_f1_m: 0.3307\n",
      "Epoch 19/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.4195 - f1_m: 0.3156 - val_loss: 1.4362 - val_f1_m: 0.5420\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.4035 - f1_m: 0.3201 - val_loss: 1.4972 - val_f1_m: 0.5062\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 4s 71ms/step - loss: 1.4002 - f1_m: 0.3587 - val_loss: 1.4672 - val_f1_m: 0.3551\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 4s 71ms/step - loss: 1.3964 - f1_m: 0.3340 - val_loss: 1.4505 - val_f1_m: 0.1955\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 4s 71ms/step - loss: 1.3820 - f1_m: 0.3473 - val_loss: 1.4549 - val_f1_m: 0.2746\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 4s 71ms/step - loss: 1.3701 - f1_m: 0.3569 - val_loss: 1.5391 - val_f1_m: 0.4650\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.3656 - f1_m: 0.3875 - val_loss: 1.4725 - val_f1_m: 0.3394\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.3573 - f1_m: 0.3740 - val_loss: 1.4381 - val_f1_m: 0.3031\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.3539 - f1_m: 0.4267 - val_loss: 1.5467 - val_f1_m: 0.3874\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.3422 - f1_m: 0.3766 - val_loss: 1.4737 - val_f1_m: 0.5139\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.3421 - f1_m: 0.4139 - val_loss: 1.5232 - val_f1_m: 0.3908\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.3224 - f1_m: 0.4160 - val_loss: 1.4846 - val_f1_m: 0.4542\n",
      "Epoch 31/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.3203 - f1_m: 0.4275 - val_loss: 1.6694 - val_f1_m: 0.5601\n",
      "Epoch 32/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.2931 - f1_m: 0.4248 - val_loss: 1.5035 - val_f1_m: 0.4298\n",
      "Epoch 33/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.2864 - f1_m: 0.4626 - val_loss: 1.5017 - val_f1_m: 0.3380\n",
      "Epoch 34/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.2719 - f1_m: 0.4483 - val_loss: 1.5667 - val_f1_m: 0.5566\n",
      "Epoch 35/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.2704 - f1_m: 0.5013 - val_loss: 1.4965 - val_f1_m: 0.5525\n",
      "Epoch 36/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.2564 - f1_m: 0.4771 - val_loss: 1.6244 - val_f1_m: 0.4941\n",
      "Epoch 37/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.2472 - f1_m: 0.4742 - val_loss: 1.6512 - val_f1_m: 0.5183\n",
      "Epoch 38/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.2406 - f1_m: 0.4987 - val_loss: 1.6723 - val_f1_m: 0.4471\n",
      "Epoch 39/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.2078 - f1_m: 0.4872 - val_loss: 1.7352 - val_f1_m: 0.5530\n",
      "Epoch 40/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.2079 - f1_m: 0.5169 - val_loss: 1.7320 - val_f1_m: 0.5442\n",
      "Epoch 41/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.1815 - f1_m: 0.5282 - val_loss: 1.7058 - val_f1_m: 0.4786\n",
      "Epoch 42/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.1710 - f1_m: 0.5485 - val_loss: 1.8418 - val_f1_m: 0.5841\n",
      "Epoch 43/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.1475 - f1_m: 0.5572 - val_loss: 1.6737 - val_f1_m: 0.4673\n",
      "Epoch 44/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.1363 - f1_m: 0.5590 - val_loss: 1.8167 - val_f1_m: 0.5194\n",
      "Epoch 45/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.1282 - f1_m: 0.5466 - val_loss: 1.8608 - val_f1_m: 0.5674\n",
      "Epoch 46/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.1176 - f1_m: 0.5700 - val_loss: 2.0140 - val_f1_m: 0.7265\n",
      "Epoch 47/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.1208 - f1_m: 0.5876 - val_loss: 1.8937 - val_f1_m: 0.5441\n",
      "Epoch 48/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.0818 - f1_m: 0.5887 - val_loss: 1.8453 - val_f1_m: 0.5757\n",
      "Epoch 49/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.0812 - f1_m: 0.5943 - val_loss: 1.8713 - val_f1_m: 0.6240\n",
      "Epoch 50/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.0715 - f1_m: 0.6187 - val_loss: 2.0223 - val_f1_m: 0.5766\n",
      "Epoch 51/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.0437 - f1_m: 0.6129 - val_loss: 1.9924 - val_f1_m: 0.5886\n",
      "Epoch 52/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.0554 - f1_m: 0.6213 - val_loss: 1.9488 - val_f1_m: 0.7355\n",
      "Epoch 53/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.0384 - f1_m: 0.6194 - val_loss: 2.1417 - val_f1_m: 0.5980\n",
      "Epoch 54/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.0206 - f1_m: 0.6543 - val_loss: 1.9935 - val_f1_m: 0.6200\n",
      "Epoch 55/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.0287 - f1_m: 0.6379 - val_loss: 2.1204 - val_f1_m: 0.6333\n",
      "Epoch 56/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.0092 - f1_m: 0.6420 - val_loss: 2.1620 - val_f1_m: 0.6664\n",
      "Epoch 57/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 1.0073 - f1_m: 0.6534 - val_loss: 1.9170 - val_f1_m: 0.5713\n",
      "Epoch 58/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9949 - f1_m: 0.6515 - val_loss: 2.0884 - val_f1_m: 0.6903\n",
      "Epoch 59/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9763 - f1_m: 0.6477 - val_loss: 2.2486 - val_f1_m: 0.6151\n",
      "Epoch 60/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9826 - f1_m: 0.6595 - val_loss: 2.2009 - val_f1_m: 0.6201\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9768 - f1_m: 0.6491 - val_loss: 2.3486 - val_f1_m: 0.6531\n",
      "Epoch 62/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9816 - f1_m: 0.6541 - val_loss: 2.2571 - val_f1_m: 0.7370\n",
      "Epoch 63/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9566 - f1_m: 0.6601 - val_loss: 2.1128 - val_f1_m: 0.6658\n",
      "Epoch 64/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9665 - f1_m: 0.6687 - val_loss: 2.3783 - val_f1_m: 0.5552\n",
      "Epoch 65/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9519 - f1_m: 0.6717 - val_loss: 2.5086 - val_f1_m: 0.6907\n",
      "Epoch 66/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9589 - f1_m: 0.6769 - val_loss: 2.4960 - val_f1_m: 0.6344\n",
      "Epoch 67/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9449 - f1_m: 0.6792 - val_loss: 2.2413 - val_f1_m: 0.6245\n",
      "Epoch 68/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9120 - f1_m: 0.6788 - val_loss: 2.6388 - val_f1_m: 0.6749\n",
      "Epoch 69/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9457 - f1_m: 0.6671 - val_loss: 2.3880 - val_f1_m: 0.6567\n",
      "Epoch 70/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9497 - f1_m: 0.6710 - val_loss: 2.3800 - val_f1_m: 0.6666\n",
      "Epoch 71/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9354 - f1_m: 0.6716 - val_loss: 2.6249 - val_f1_m: 0.7483\n",
      "Epoch 72/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9165 - f1_m: 0.6789 - val_loss: 2.2058 - val_f1_m: 0.5471\n",
      "Epoch 73/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9350 - f1_m: 0.6645 - val_loss: 2.3012 - val_f1_m: 0.7608\n",
      "Epoch 74/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9006 - f1_m: 0.6994 - val_loss: 2.5213 - val_f1_m: 0.7016\n",
      "Epoch 75/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.8875 - f1_m: 0.6986 - val_loss: 2.3139 - val_f1_m: 0.7485\n",
      "Epoch 76/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.9024 - f1_m: 0.6795 - val_loss: 2.4052 - val_f1_m: 0.6498\n",
      "Epoch 77/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.8564 - f1_m: 0.7030 - val_loss: 2.7467 - val_f1_m: 0.6849\n",
      "Epoch 78/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.8683 - f1_m: 0.6949 - val_loss: 2.1968 - val_f1_m: 0.6610\n",
      "Epoch 79/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.8490 - f1_m: 0.6972 - val_loss: 2.7574 - val_f1_m: 0.7079\n",
      "Epoch 80/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.8390 - f1_m: 0.7242 - val_loss: 2.5779 - val_f1_m: 0.6824\n",
      "Epoch 81/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.8377 - f1_m: 0.6917 - val_loss: 2.6176 - val_f1_m: 0.7357\n",
      "Epoch 82/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.8192 - f1_m: 0.7091 - val_loss: 2.8908 - val_f1_m: 0.7257\n",
      "Epoch 83/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.8300 - f1_m: 0.7039 - val_loss: 2.6710 - val_f1_m: 0.7152\n",
      "Epoch 84/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.8010 - f1_m: 0.7107 - val_loss: 2.7608 - val_f1_m: 0.7817\n",
      "Epoch 85/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.8093 - f1_m: 0.7169 - val_loss: 2.7829 - val_f1_m: 0.7282\n",
      "Epoch 86/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7831 - f1_m: 0.7196 - val_loss: 2.7244 - val_f1_m: 0.7072\n",
      "Epoch 87/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7883 - f1_m: 0.7304 - val_loss: 2.8812 - val_f1_m: 0.7047\n",
      "Epoch 88/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7750 - f1_m: 0.7188 - val_loss: 2.7539 - val_f1_m: 0.6803\n",
      "Epoch 89/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7685 - f1_m: 0.7316 - val_loss: 2.7108 - val_f1_m: 0.7149\n",
      "Epoch 90/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7949 - f1_m: 0.7149 - val_loss: 2.9153 - val_f1_m: 0.8012\n",
      "Epoch 91/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7620 - f1_m: 0.7304 - val_loss: 2.8055 - val_f1_m: 0.6745\n",
      "Epoch 92/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7438 - f1_m: 0.7384 - val_loss: 3.0057 - val_f1_m: 0.7029\n",
      "Epoch 93/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7352 - f1_m: 0.7378 - val_loss: 2.7207 - val_f1_m: 0.6949\n",
      "Epoch 94/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7175 - f1_m: 0.7355 - val_loss: 3.0297 - val_f1_m: 0.6867\n",
      "Epoch 95/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7481 - f1_m: 0.7380 - val_loss: 2.8976 - val_f1_m: 0.7542\n",
      "Epoch 96/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7155 - f1_m: 0.7315 - val_loss: 3.4644 - val_f1_m: 0.8153\n",
      "Epoch 97/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7306 - f1_m: 0.7449 - val_loss: 2.9959 - val_f1_m: 0.7393\n",
      "Epoch 98/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7430 - f1_m: 0.7500 - val_loss: 2.9383 - val_f1_m: 0.7197\n",
      "Epoch 99/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.7155 - f1_m: 0.7369 - val_loss: 2.6374 - val_f1_m: 0.7463\n",
      "Epoch 100/100\n",
      "56/56 [==============================] - 4s 70ms/step - loss: 0.6894 - f1_m: 0.7589 - val_loss: 3.0645 - val_f1_m: 0.7560\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,  # 검증 데이터셋 추가\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6feae1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 29ms/step - loss: 3.1759 - f1_m: 0.7589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.175852060317993, 0.7589392066001892]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55406bd6",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5acd4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vec = model(token_id_test)\n",
    "y_pred = np.argmax(result_vec, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0f5c61ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1380647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(y_pred, user_name, f1_score=None):\n",
    "    data_path =\"/aiffel/aiffel/dlthon_team5/data\"\n",
    "    save_path =\"/aiffel/aiffel/dlthon_team5/submission\"\n",
    "    submission_path = join(data_path, 'new_submission.csv')\n",
    "    submission = pd.read_csv(submission_path)\n",
    "    submission.columns = ['idx', 'target']\n",
    "    submission['target'] = y_pred\n",
    "    submission_csv_path = '{}/submission_{}_f1score_{}.csv'.format(save_path, user_name, f1_score)\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "    print('{} saved!'.format(submission_csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f2a2a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/dlthon_team5/submission/submission_phc_v1_f1score_75.csv saved!\n"
     ]
    }
   ],
   "source": [
    "save_submission(y_pred,'phc_v1','75')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2718b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed670bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
