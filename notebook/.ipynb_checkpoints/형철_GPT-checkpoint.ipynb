{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4754fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28.1 in /opt/conda/lib/python3.9/site-packages (0.28.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from openai==0.28.1) (4.62.3)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from openai==0.28.1) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.9/site-packages (from openai==0.28.1) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20->openai==0.28.1) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20->openai==0.28.1) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20->openai==0.28.1) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20->openai==0.28.1) (2.10)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->openai==0.28.1) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->openai==0.28.1) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->openai==0.28.1) (5.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->openai==0.28.1) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->openai==0.28.1) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->openai==0.28.1) (1.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/lib/python3.9/site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->openai==0.28.1) (4.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c544ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "with open (\"../data/test.json\", \"r\") as f:\n",
    "    test_df = json.load(f)\n",
    "\n",
    "test = pd.DataFrame(test_df).T.reset_index().rename(columns={\"index\":\"file_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe43c8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{이유: 상대방에게 제대로 할 것을 요구하는 표현이 포함되어 있음, 태그: {갈취 대화: 1}}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# API 키 설정\n",
    "openai.api_key = \"your code\"\n",
    "\n",
    "# ChatGPT 모델 호출 예시\n",
    "\n",
    "def chat_gpt_028(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"user\", \"content\": '너는 친절한 어시스턴스야, 그리고 엄청 꼼꼼하게 다음 임무를 수행할수있어, 다음 문장을 5가지 분류중 하나로 분리해서 다음 태그중 하나로 대답해줘 태그는 다음과 같아 {협박 대화: 0}, {갈취 대화: 1}, {직장 내 괴롭힘 대화: 2}, {기타 괴롭힘 대화: 3}, {일반 대화: 4} 분류한 근거를 한문장으로 찾아서 답변해줘 다음 답변 포맷을 무조건 지켜야해! {이유 : , 태그 : } , 답변 예시 {이유 : 직장임이 암시되어있으며 괴롭힘 표현이 존재, 태그 : {직장 내 괴롭힘 : 2}} 다음은 분류에 도움이되는 기준예시를 몇개 들어줄게 협박은 위협하는 뉘앙스야  신체적인 요소에 해를 가하려한다던지 그런 표현이 들어가있어 아니면 본인이 죽겠다고 한다던지, 갈취는 어떤 물건이나 돈을 뺏으려고 하거나 부당하게 얻으려고 하는 뉘앙스가 있으면 갈취야 사소한 표현이 들어가있어도 이득을 얻으려는 뉘앙스가있다면 갈취로 해줘, 직장내 괴롭힘은 괴롭힘의 문장이 들어가있는데 문장내에 직장임을 알수있는 점이 무조건있어 만약 직장임이 애매하다면 기타괴롭힘으로 넘어가야되!,  괴롭힘의 문장이있는데 직장상황이 아닌것같으면(학교에서 발생하는 문제라던가) 기타 괴롭힘 상황으로 분류해줘, 나머지는 일반대화로 분류해줘 예시 끝 이 예시를 바탕으로 다음 문장을 보고 다음 답변 포맷에 맞춰서 대답해줘 {이유 : , 태그 : } 태그에는 무조건 숫자가 포함되어야해' },\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "query = test.iloc[2]['text']\n",
    "answer = chat_gpt_028(query)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f57c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나보네 그럼 취소할까요 아가씨 내 여기단골이니 담에 갖다줄께 저도 알바생이라 외상안됩니다 아따 누가 떼먹는다고 그러나 갖다준다고 안됩니다 자꾸이럼 경찰불러요 아가씨 담배피는교 그건 왜 물으세요 그람 아가씨 담배 한대만 빌립시다 내 지금 지갑도 잃어버리고 기분이 그래서 그러니 여기요  아따 주는김에 한개더 주면 되겠네\n",
      "{이유 : 도난당한 상황 및 암시적 협박 표현 존재, 태그 : {협박 대화: 0}}\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "\n",
    "print(test.iloc[ii]['text'])\n",
    "query = test.iloc[ii]['text']\n",
    "answer = chat_gpt_028(query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e99be32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chat_gpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3542896090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chat_gpt' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "y_pred = []\n",
    "for i in range(len(test)):\n",
    "    query = test.iloc[i]['text']\n",
    "    answer = chat_gpt(query)\n",
    "    numbers = re.findall(r'\\d+', answer)\n",
    "    y_pred.append(int(numbers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2a4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1ed72ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 500\n",
      "['1']\n",
      "1 / 500\n",
      "['2']\n",
      "2 / 500\n",
      "['2']\n",
      "3 / 500\n",
      "['4']\n",
      "4 / 500\n",
      "['4']\n",
      "5 / 500\n",
      "['0']\n",
      "6 / 500\n",
      "['0']\n",
      "7 / 500\n",
      "['1']\n",
      "8 / 500\n",
      "['4']\n",
      "9 / 500\n",
      "['1']\n",
      "10 / 500\n",
      "['0']\n",
      "11 / 500\n",
      "['4']\n",
      "12 / 500\n",
      "['2']\n",
      "13 / 500\n",
      "['4']\n",
      "14 / 500\n",
      "['2']\n",
      "15 / 500\n",
      "['0']\n",
      "16 / 500\n",
      "['4']\n",
      "17 / 500\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for gpt-4 in organization org-IfIJat1RayQUvr4uu5crsImb on tokens per min (TPM): Limit 10000, Used 9529, Requested 511. Please try again in 240ms. Visit https://platform.openai.com/account/rate-limits to learn more.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/973501528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/ 500'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_gpt_028\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_reason\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/2770609425.py\u001b[0m in \u001b[0;36mchat_gpt_028\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchat_gpt_028\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         messages=[\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         )\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             return (\n\u001b[0;32m--> 710\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    711\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    776\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for gpt-4 in organization org-IfIJat1RayQUvr4uu5crsImb on tokens per min (TPM): Limit 10000, Used 9529, Requested 511. Please try again in 240ms. Visit https://platform.openai.com/account/rate-limits to learn more."
     ]
    }
   ],
   "source": [
    "import re\n",
    "y_pred = []\n",
    "y_reason = []\n",
    "for i in range(len(test)):\n",
    "    print(i, '/ 500')\n",
    "    query = test.iloc[i]['text']\n",
    "    answer = chat_gpt_028(query)\n",
    "    numbers = re.findall(r'\\d+', answer)\n",
    "    y_reason.append(answer)\n",
    "    print(numbers)\n",
    "    y_pred.append(int(numbers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "512164e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 0, 2, 4, 4, 0, 0, 1, 4, 1, 0, 4, 2, 4, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d851e476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{이유 : 일반적인 상품 거래를 나타내며, 그 과정에서 발생하는 사건을 설명하는 일상 대화, 태그 : {일반 대화 : 4}}',\n",
       " '{이유 : 직장에서 발생하는 과도한 희생을 강요하다가 협박으로 이어지는 상황, 태그 : {협박 대화 : 0}}',\n",
       " \"{이유 : 상사와 부하 사이의 대화로 보이며 '제대로 좀 하지', '똑바로 좀 하지' 등 괴롭힘에 가까운 발언이 있음, 태그 : {직장 내 괴롭힘 대화: 2}}\",\n",
       " '{이유 : 특별한 위협, 갈취, 괴롭힘의 뉘앙스가 없으며 일상 대화가 주를 이룸, 태그 : {일반 대화: 4}}',\n",
       " '{이유 : 대화에서 협박, 갈취, 괴롭힘 등의 뉘앙스가 없고 일상적인 대화의 흐름을 보여주고 있습니다, 태그 : {일반 대화: 4}}',\n",
       " '{이유 : 위협하는 뉘앙스와 폭력이 포함된 대화, 태그 : {협박 대화: 0}}',\n",
       " '{이유 : 대화 내용에서 협박하고 위협하는 뉘앙스가 드러나고 있음, 태그 : {협박 대화: 0}}',\n",
       " '{이유 : 돈을 부당하게 얻으려고 하는 뉘앙스가 있음, 태그 : {갈취 대화: 1}}',\n",
       " '{이유 : 특별한 문제점이나 괴롭힘, 협박, 갈취 등의 내용이 없음, 태그 : {일반 대화: 4}}',\n",
       " '{이유 : 대화를 통해 학교에서 이루어진 것으로 보이며 물건이나 돈을 뺏으려는 뉘앙스가 포함되어있음, 태그 : {갈취 대화: 1}}',\n",
       " '{이유 : 문장에 상황을 위협하는 경우가 잦음, 태그 : {협박 대화: 0}}',\n",
       " '{이유 : 직장을 얻고 싶다는 대화내용이지만 협박, 갈취 또는 괴롭힘의 요소가 들어있지 않음, 태그 : {일반 대화: 4}}',\n",
       " '{이유 : 상사가 비서에게 부당한 지시를 내렸고, 이를 거부하는 상황이기 때문에 직장 내에서 괴롭힘 발생, 태그 : {직장 내 괴롭힘 대화: 2}}',\n",
       " '{이유 : 직장 상황에서 상사에 대한 부정적인 감정이 언급되었지만, 구체적인 괴롭힘 표현이 누락되어 있어 일반 대화로 추정, 태그 : {일반 대화: 4}}',\n",
       " '{이유 : 문장 내에 직장 체계와 과장 대리의 관계가 암시되어 있으며 과장님이 대리를 괴롭히는 뉘앙스가 느껴짐, 태그 : {직장 내 괴롭힘 대화: 2}}']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "547e6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "def save_submission(y_pred, user_name, f1_score=None):\n",
    "    data_path =\"/aiffel/aiffel/dlthon_team5/data\"\n",
    "    save_path =\"/aiffel/aiffel/dlthon_team5/submission\"\n",
    "    submission_path = join(data_path, 'new_submission.csv')\n",
    "    submission = pd.read_csv(submission_path)\n",
    "    submission.columns = ['idx', 'target']\n",
    "    submission['target'] = y_pred\n",
    "    submission_csv_path = '{}/submission_{}_f1score_{}.csv'.format(save_path, user_name, f1_score)\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "    print('{} saved!'.format(submission_csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f22db1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/dlthon_team5/submission/submission_phc_gpt_v1_f1score_None.csv saved!\n"
     ]
    }
   ],
   "source": [
    "save_submission(y_pred,'phc_gpt_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "968b09f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['labels'] = y_pred\n",
    "test['reason'] = y_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe4c7b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>t_495</td>\n",
       "      <td>미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>t_496</td>\n",
       "      <td>교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>t_497</td>\n",
       "      <td>야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>t_498</td>\n",
       "      <td>야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>t_499</td>\n",
       "      <td>엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name                                               text  labels\n",
       "0       t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...       1\n",
       "1       t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...       2\n",
       "2       t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...       2\n",
       "3       t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...       4\n",
       "4       t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...       1\n",
       "..        ...                                                ...     ...\n",
       "495     t_495  미나씨 휴가 결제 올리기 전에 저랑 상의하라고 말한거 기억해요? 네 합니다. 보고서...       2\n",
       "496     t_496  교수님 제 논문에 제 이름이 없나요?  아 무슨 논문말이야?  지난 번 냈던 논문이...       2\n",
       "497     t_497  야 너  네 저요? 그래 너 왜요 돈좀 줘봐  돈 없어요 돈이 왜 없어 지갑은 폼이...       1\n",
       "498     t_498  야 너 빨리 안 뛰어와? 너 이 환자 제대로 봤어 안 봤어 어제 저녁부터 계속 보다...       2\n",
       "499     t_499  엄마 저 그 돈 안해주시면 정말 큰일나요.  이유도 말하지 않고. 몇번째니 경민아....       0\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec1164dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path =\"/aiffel/aiffel/dlthon_team5/submission\"\n",
    "user_name = 'phc'\n",
    "test_csv_path = submission_csv_path = '{}/test_{}_gpt_result2.csv'.format(save_path, user_name)\n",
    "test.to_csv(test_csv_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4cdc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
